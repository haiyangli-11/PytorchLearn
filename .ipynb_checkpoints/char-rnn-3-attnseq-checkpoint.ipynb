{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T02:39:37.177380Z",
     "start_time": "2021-04-02T02:39:36.758807Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T03:39:54.101438Z",
     "start_time": "2021-04-02T03:39:54.096198Z"
    }
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    \"\"\"\n",
    "    name:语言名称\n",
    "    index2word:标索引单词\n",
    "    word2index：单词索引下标\n",
    "    word2count：单词索引单次数量\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0: 'SOS_token', 1: 'EOS_token'}\n",
    "        self.word2count = {}\n",
    "        self.n_word = 2\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index.keys():\n",
    "            self.index2word[self.n_word] = word\n",
    "            self.word2index[word] = self.n_word\n",
    "            self.word2count[word] = 1\n",
    "            self.n_word += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T03:40:23.187061Z",
     "start_time": "2021-04-02T03:40:23.183191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicode2ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = unicode2ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T03:49:43.358653Z",
     "start_time": "2021-04-02T03:49:39.629255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading lines of language eng to fra\n",
      "[['go .', 'va !'], ['run !', 'cours !'], ['run !', 'courez !'], ['wow !', 'ca alors !'], ['fire !', 'au feu !']]\n"
     ]
    }
   ],
   "source": [
    "def readLang(lan1, lan2):\n",
    "    \"\"\"\n",
    "    读取文本文件，返回两个语言类Lang实例和对应的成对的语言列表\n",
    "    \"\"\"\n",
    "    print(\"reading lines of language %s to %s\" % (lan1, lan2))\n",
    "\n",
    "    with open('./data/eng-fra.txt', encoding='UTF-8') as f:\n",
    "        lines = f.readlines()\n",
    "    pairs = []\n",
    "    for line in lines:\n",
    "        sentences = line.strip().split('\\t')\n",
    "        if len(sentences) < 2:\n",
    "            print(line)\n",
    "            print('-------error!------')\n",
    "            exit(-1)\n",
    "        pairs.append([\n",
    "            normalize_string(sentences[0].strip()),\n",
    "            normalize_string(sentences[1].strip())\n",
    "        ])\n",
    "    lang_src = Lang(lan1)\n",
    "    lang_dst = Lang(lan2)\n",
    "#     for pair in pairs:\n",
    "#         lang_src.add_sentence(pair[0])\n",
    "#         lang_dst.add_sentence(pair[1])\n",
    "\n",
    "    return lang_src, lang_dst, pairs\n",
    "\n",
    "\n",
    "lang_src, lang_dst, lang_pairs = readLang('eng', 'fra')\n",
    "print(lang_pairs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T03:49:44.853265Z",
     "start_time": "2021-04-02T03:49:44.850636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(lang_pairs[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T03:50:08.839355Z",
     "start_time": "2021-04-02T03:50:08.726269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95170\n"
     ]
    }
   ],
   "source": [
    "MAX_WORD = 10\n",
    "\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [\n",
    "        pair for pair in pairs if len(pair[0].split(' ')) < MAX_WORD\n",
    "        and len(pair[1].split(' ')) < MAX_WORD\n",
    "    ]\n",
    "\n",
    "lang_pairs = filter_pairs(lang_pairs)\n",
    "print(len(lang_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T03:53:22.751624Z",
     "start_time": "2021-04-02T03:53:22.225304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng 10025\n",
      "fra 16813\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for pair in lang_pairs:\n",
    "    lang_src.add_sentence(pair[0])\n",
    "    lang_dst.add_sentence(pair[1])\n",
    "\n",
    "print(lang_src.name, lang_src.n_word)\n",
    "print(lang_dst.name, lang_dst.n_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRnn(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input_data, hidden):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 283,
   "position": {
    "height": "305px",
    "left": "1166px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
